{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import keras  \n",
    "from keras.datasets import mnist \n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Input, Conv2D, MaxPooling2D, Dropout, Flatten \n",
    "from keras import backend as k\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading MNIST data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Data Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "Number of images in x_train 60000\n",
      "Number of images in x_test 10000\n"
     ]
    }
   ],
   "source": [
    "img_row, img_col= (28, 28)\n",
    "\n",
    "\"\"\"\n",
    "    img_row and img_col are image dimensions and in MNIST dataset it is 28 x 28\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# The ordering of the dimensions in input\n",
    "\n",
    "if k.image_data_format() == 'channels_first':\n",
    "        \n",
    "    \"\"\"  channel_first : corrspond to inputs with shapes (batch, channels, height, width)  \"\"\"\n",
    "\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_row, img_col) \n",
    "    x_test  = x_test.reshape(x_test.shape[0], 1, img_row, img_col) \n",
    "    np = (1, img_row, img_col) \n",
    "    \n",
    "\n",
    "else:\n",
    "\n",
    "    \"\"\"  channel_last :  corrspond to inputs with shapes (batch, height, width, channels) \"\"\"\n",
    "    \n",
    "    x_train = x_train.reshape(x_train.shape[0], img_row, img_col, 1) \n",
    "    x_test = x_test.reshape(x_test.shape[0], img_row, img_col, 1) \n",
    "    np = (img_row, img_col, 1) \n",
    "    \n",
    "\n",
    "    \n",
    "# Setting the float values so it is possible to get get decimal points after division\n",
    "\n",
    "x_train = x_train.astype('float32') \n",
    "x_test  = x_test.astype('float32') \n",
    "\n",
    "\n",
    "\n",
    "x_train /= 255    # Normalizing:The max RGB value is 255\n",
    "x_test  /= 255    # Normalizing:The max RGB value is 255\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('Number of images in x_train', x_train.shape[0])\n",
    "print('Number of images in x_test', x_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ny_train = keras.utils.to_categorical(y_train) \\ny_test = keras.utils.to_categorical(y_test) \\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Our model cannot work with categorical data directly. \n",
    "We need to use one hot encoding. \n",
    "In one hot encoding, the digits 0 \n",
    "through 9 are represented as \n",
    "a set of nine zeros and a single one. \n",
    "The digit is determined by the location \n",
    "of the number 1. For example, you’d \n",
    "represent a 3 as [0, 0, 0, 1, 0, 0, 0, 0, 0, 0].\n",
    "\"\"\"\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "\"\"\"\n",
    "y_train = keras.utils.to_categorical(y_train) \n",
    "y_test = keras.utils.to_categorical(y_test) \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model : using \"Model\" from keras.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 22s 369us/step - loss: 0.7036 - accuracy: 0.7852\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 22s 363us/step - loss: 0.2194 - accuracy: 0.9370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f4e0d77ba58>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Building CNN \n",
    "\n",
    "np     = Input(shape = np) \n",
    "layer1 = Conv2D(32, kernel_size=(3, 3), activation='relu')(np) \n",
    "\"\"\"\n",
    "layer1: Conv2d layer which convolves \n",
    "the image using 32 filters each of size (3*3)\n",
    "\"\"\"\n",
    "layer2 = Conv2D(64, (3, 3), activation='relu')(layer1)\n",
    "\"\"\"\n",
    "layer2: Conv2D layer which convolve \n",
    "the image and is using 64 filters each of size (3*3)\n",
    "\"\"\"\n",
    "\n",
    "layer3 = MaxPooling2D(pool_size=(3, 3))(layer2)\n",
    "\"\"\"\n",
    "layer3: MaxPooling2D layer which picks \n",
    "the max value out of a matrix of size (3*3)\n",
    "\"\"\"\n",
    "layer4 = Dropout(0.5)(layer3) \n",
    "\"\"\"\n",
    "layer4: shows Dropout at a rate of 0.5\n",
    "\"\"\"\n",
    "layer5 = Flatten()(layer4) \n",
    "\"\"\"\n",
    "layer5: flatten the output obtained from layer4 \n",
    "and this flatten output is passed to layer6\n",
    "\"\"\"\n",
    "layer6 = Dense(250, activation = 'sigmoid')(layer5) \n",
    "\"\"\"\n",
    "layer6: shows a hidden layer of neural network containng 250 neurons.\n",
    "\"\"\"\n",
    "layer7 = Dense(10, activation = 'softmax')(layer6) \n",
    "\"\"\"\n",
    "layer7: shows output layer having 10 neurons for 10 \n",
    "classes of output that is using the softmax function\n",
    "the final Dense layer must have 10 neurons since we \n",
    "have 10 number classes (0, 1, 2, …, 9)\n",
    "\"\"\"\n",
    "\n",
    "#  Compiling and Fitting\n",
    "\n",
    "model = Model([np], layer7) \n",
    "model.compile(optimizer=keras.optimizers.Adadelta(), \n",
    "              loss=keras.losses.categorical_crossentropy,\n",
    "              metrics=['accuracy']) \n",
    "model.fit(x = x_train, y = y_train, epochs=2, batch_size=500) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evalute Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss = 0.12297678209245205\n",
      "Test accuracy = 0.9646000266075134\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0) \n",
    "print('Test loss =', test_loss) \n",
    "print('Test accuracy =', test_acc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making an Individual Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_index = 3456\n",
    "plt.imshow(x_test[image_index].reshape(28, 28),cmap='Greys')\n",
    "pred = model.predict(x_test[image_index].reshape(1, img_row, img_col, 1))\n",
    "print(pred.argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading MNIST data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model : using Sequential model from Keras and TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 14s 232us/step - loss: 0.1960 - accuracy: 0.9405\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 14s 230us/step - loss: 0.0813 - accuracy: 0.9743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f4e0ffbbfd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshaping the array to 4-dims so that it can work with the Keras API\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# Setting the float values so it is possible to get get decimal points after division\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "\n",
    "x_train /= 255    # Normalizing:The max RGB value is 255\n",
    "x_test /= 255     # Normalizing:The max RGB value is 255\n",
    "\n",
    "\n",
    "# Sequential Model and relevant layers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3,3), input_shape = input_shape))\n",
    "\"\"\"\n",
    "layer1: Conv2d layer which convolves \n",
    "the image using 64 filters each of size (3*3)\n",
    "\"\"\"\n",
    "model.add(MaxPooling2D(pool_size = (3, 3)))\n",
    "\"\"\"\n",
    "layer2: MaxPooling2D layer which picks \n",
    "the max value out of a matrix of size (3*3)\n",
    "Maxpooling is one of the most common techniques\n",
    "to reduce the spatial size of the representation,\n",
    "to reduce the parameter counts which reduces the\n",
    "computational complexity. In addition, pooling \n",
    "layers also helps with the overfitting problem. \n",
    "\"\"\"\n",
    "model.add(Dropout(0.5))\n",
    "\"\"\"\n",
    "layer3: shows Dropout at a rate of 0.5\n",
    "Dropout layers fight with the overfitting \n",
    "by disregarding some of the neurons while training\n",
    "\"\"\"\n",
    "model.add(Flatten())\n",
    "\"\"\"\n",
    "layer4: flatten the output obtained from layer3 \n",
    "and this flatten output is passed to layer5\n",
    "\"\"\"\n",
    "model.add(Dense(128, activation = tf.nn.relu))\n",
    "\"\"\"\n",
    "layer5: shows a hidden layer of neural network containng 128 neurons\n",
    "\"\"\"\n",
    "model.add(Dense(10, activation = tf.nn.softmax))\n",
    "\"\"\"\n",
    "layer6: shows output layer having 10 neurons for 10 \n",
    "classes of output that is using the softmax function\n",
    "the final Dense layer must have 10 neurons since we \n",
    "have 10 number classes (0, 1, 2, …, 9)\n",
    "\"\"\"\n",
    "\n",
    "# Compiling and Fitting\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x = x_train,y = y_train, epochs = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evalute Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss = 0.09513569734748453\n",
      "Test accuracy = 0.9689000248908997\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0) \n",
    "print('Test loss =', test_loss) \n",
    "print('Test accuracy =', test_acc) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
