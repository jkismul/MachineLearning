{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ridge svd?\n",
    "\n",
    "#np.roll idea needs adjustment for last fold, maybe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import numpy as np\n",
    "from random import random, seed\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.linear_model as skl\n",
    "import scipy.linalg as scl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define Franke function uglified\n",
    "def FrankeFunction(x,y): #still got one division in here\n",
    "    term1 = 0.75*np.exp(-(0.25*(9*x-2)*(9*x-2)) - 0.25*((9*y-2)*(9*y-2)))\n",
    "    term2 = 0.75*np.exp(-((9*x+1)*(9*x+1))/49.0 - 0.1*(9*y+1))\n",
    "    term3 = 0.5*np.exp(-(9*x-7)*(9*x-7)*0.25 - 0.25*((9*y-3)*(9*y-3)))\n",
    "    term4 = -0.2*np.exp(-(9*x-4)*(9*x-4) - (9*y-7)*(9*y-7))\n",
    "    return term1 + term2 + term3 + term4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model matrix\n",
    "# Form is: x0y0, x1y0, x2y0, x0y1, x1y1, x0y2\n",
    "def Model(x,y,P): # P is polynomial degree\n",
    "    m = len(x)*len(y) # number of equations\n",
    "    t = sum(range(P+2)) # number of terms in polynomial\n",
    "    X = np.zeros((m,t)) # Model matrix\n",
    "    a = np.matrix.flatten(x)\n",
    "    b = np.matrix.flatten(y)\n",
    "    c = 0 #counter\n",
    "    for i in range(P+1):\n",
    "        for j in range(P+1-i):\n",
    "            X[:,c] = a**j*b**i\n",
    "            c +=1\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ols_svd(X: np.ndarray, z: np.ndarray,_lambda) -> np.ndarray:\n",
    "    u, s, v = scl.svd(X)\n",
    "    pin = scl.diagsvd(1./s,len(v),len(u))\n",
    "#     return v.T @ scl.pinv(scl.diagsvd(s, u.shape[0], v.shape[0])) @ u.T @ z\n",
    "    return v.T @ pin @ u.T @ z\n",
    "#pinx xt x\n",
    "# THIS ALGO NEEDS IMPROVEMENT! QR decomp\n",
    "\n",
    "#same results as skl up to and including mpd14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ols_inv(X: np.ndarray, z: np.ndarray) -> np.ndarray:\n",
    "    return scl.inv(X.T @ X) @ (X.T @ z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define R2 function\n",
    "def R2(y_data, y_model):\n",
    "    return 1 - np.sum((y_data - y_model) ** 2) / np.sum((y_data - np.mean(y_data)) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define MSE function\n",
    "def MSE(y_data,y_model):\n",
    "    n = np.size(y_model)\n",
    "    return np.sum((y_data-y_model)**2)/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define variance function\n",
    "def Var(y_data, y_model,P,X):\n",
    "    N = len(y_data)\n",
    "    covar = np.linalg.inv(X.T.dot(X))#sigma2, should be 1 in this case\n",
    "    vari = np.diagonal(covar)\n",
    "    return vari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Var2(y_data,y_model,n):\n",
    "    m = len(y_data)\n",
    "    res = y_data-y_model\n",
    "    return (1./(m-n-1))*(res.T@res)\n",
    "#     return np.mean(y_model**2)-np.mean(yh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bias(y_data, y_model, P, X):\n",
    "    N = len(y_data) #should probably insert z here\n",
    "    # also want the expectation values\n",
    "    #this is where i want to shuffle my data and do 10 kfolds.\n",
    "    #maybe...\n",
    "    #can not use each fold and create a mean from them?\n",
    "    return np.sum((y_data-y_model)*(y_data-y_model))/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bias2(y_data,y_model):\n",
    "    n = len(y_data)\n",
    "    return np.sum((y_data-(np.mean(y_model)))**2)/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create random variables/predictors\n",
    "# np.random.seed(1234)\n",
    "N = 20  #number of points along x and y axes\n",
    "\n",
    "# sort this for meshgrid\n",
    "x = np.random.uniform(0,1,N)\n",
    "y = np.random.uniform(0,1,N)\n",
    "\n",
    "x = sorted(x)\n",
    "y = sorted(y)\n",
    "x, y = np.meshgrid(x,y,sparse=False)\n",
    "\n",
    "#create datapoints/results\n",
    "z = FrankeFunction(x, y)\n",
    "\n",
    "# Create noise\n",
    "Noise = 0.1*np.random.randn(N,N)\n",
    "\n",
    "#add noise\n",
    "z_n = z+Noise\n",
    "\n",
    "#flatten for use in functions\n",
    "z_n = np.matrix.flatten(z_n)\n",
    "z = np.matrix.flatten(z)\n",
    "\n",
    "#added a 0 Ridge parameter\n",
    "_lambda = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "MPD =10#maximal polynomial degree\n",
    "\n",
    "X = Model(x,y,MPD) #create model matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NoResampling(X,z_n,_lambda):\n",
    "#     beta = np.linalg.inv(X.T.dot(X)-_lambda*np.eye(len(X[0][:]))).dot(X.T).dot(z_n)\n",
    "#     beta = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(z_n)\n",
    "    beta = ols_svd(X,z_n,_lambda)\n",
    "#     beta = ols_inv(X,z_n)\n",
    "    ztilde = X @ beta\n",
    "\n",
    "    return MSE(z_n,ztilde), R2(z_n,ztilde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.008150832337056508, 0.8947118424250515)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NoResampling(X,z_n,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find parameters\n",
    "# beta = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(z_n)\n",
    "beta = ols_svd(X,z_n,_lambda)\n",
    "## make prediction\n",
    "ztilde = X @ beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "######  Makes model matrix, looks different than mine #####\n",
    "# form: x0y0, x1y0, x0y1, x2y0, x1y1, x0y2\n",
    "# poly2 = PolynomialFeatures(degree=MPD)\n",
    "# a = x[:,np.newaxis]\n",
    "# b = y[:,np.newaxis]\n",
    "# cc = np.c_[a,b]\n",
    "# Xskl = poly2.fit_transform(cc) \n",
    "##########################################################\n",
    "# THIS CELL IS CURRENTLY NOT IN USE #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find parameters\n",
    "clf = skl.LinearRegression(fit_intercept=False) #False to not center data, i.e. intercept is not 0\n",
    "clf.fit(X,z_n) \n",
    "\n",
    "#make prediction\n",
    "zpredict = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error (self): 0.01095\n",
      "Mean squared error (skl): 0.01095\n",
      "R2 score (self): 0.87434\n",
      "R2 score (skl): 0.87434\n"
     ]
    }
   ],
   "source": [
    "# The mean squared error              \n",
    "print(\"Mean squared error (self): %.5f\" % MSE(z_n, ztilde))\n",
    "print(\"Mean squared error (skl): %.5f\" % mean_squared_error(z_n, zpredict))\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction     \n",
    "print('R2 score (self): %.5f' %R2(z_n, ztilde))\n",
    "print('R2 score (skl): %.5f' % r2_score(z_n, zpredict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.37595934e+00 1.14261493e+02 2.40112552e+03 1.28726789e+04\n",
      " 1.44291418e+04 2.18571532e+03 3.61461887e+02 2.53556462e+03\n",
      " 6.01782767e+03 4.89384260e+03 8.66559213e+02 7.80593180e+03\n",
      " 1.14673676e+04 8.56265875e+03 1.03992207e+03 3.61366777e+04\n",
      " 1.02936988e+04 2.07883713e+03 3.53434180e+04 1.71350220e+03\n",
      " 4.80249246e+03]\n",
      "[2.37595934e+00 1.14261493e+02 2.40112552e+03 1.28726789e+04\n",
      " 1.44291418e+04 2.18571532e+03 3.61461887e+02 2.53556462e+03\n",
      " 6.01782767e+03 4.89384260e+03 8.66559213e+02 7.80593180e+03\n",
      " 1.14673676e+04 8.56265875e+03 1.03992207e+03 3.61366777e+04\n",
      " 1.02936988e+04 2.07883713e+03 3.53434180e+04 1.71350220e+03\n",
      " 4.80249246e+03]\n"
     ]
    }
   ],
   "source": [
    "print(Var(z_n, ztilde, MPD,X)) #my variances in betas\n",
    "print(Var(z_n,zpredict,MPD,X)) #skl variances in betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.27248503   7.89793843 -36.54968178  56.3501057  -34.38445574\n",
      "   6.48635214   6.11669947 -17.70109348  46.72441349 -52.7761958\n",
      "  17.75811044 -16.06396127  24.18640356 -14.35813375  11.97638168\n",
      "   3.80210871 -24.11352472  -2.39718131  17.14478568  10.70838136\n",
      " -11.08225171]\n",
      "[  0.27248503   7.89793843 -36.54968178  56.3501057  -34.38445574\n",
      "   6.48635214   6.11669947 -17.70109348  46.72441349 -52.7761958\n",
      "  17.75811044 -16.06396127  24.18640356 -14.35813375  11.97638168\n",
      "   3.80210871 -24.11352472  -2.39718131  17.14478568  10.70838136\n",
      " -11.08225171]\n"
     ]
    }
   ],
   "source": [
    "print(beta) #my betas\n",
    "print(clf.coef_) #skl betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2724850306318026 3.021172853149135\n",
      "7.897938427265337 20.95106085083251\n",
      "-36.5496817844621 96.04251043643849\n",
      "56.35010570156706 222.37734405981226\n",
      "-34.384455738280366 235.4378707661387\n",
      "6.4863521356560945 91.63320335730295\n",
      "6.1166994742845775 37.26381602822263\n",
      "-17.701093483150185 98.69460492438644\n",
      "46.72441348924867 152.04633099131036\n",
      "-52.77619579508718 137.1137692821534\n",
      "17.758110438273423 57.69726054372396\n",
      "-16.063961265456093 173.16832163351935\n",
      "24.186403561208802 209.88815928130876\n",
      "-14.358133745722899 181.36788543186978\n",
      "11.97638167955756 63.20573267263559\n",
      "3.802108705997348 372.5891314811888\n",
      "-24.113524722212283 198.8574191333822\n",
      "-2.397181314066359 89.3647620975117\n",
      "17.144785676478165 368.47696626515517\n",
      "10.708381358109937 81.13316256411738\n",
      "-11.082251705298152 135.82803474777634\n"
     ]
    }
   ],
   "source": [
    "std = 1.96*np.sqrt(Var(z_n, ztilde, MPD,X))\n",
    "\n",
    "for i in range(len(std)):\n",
    "    print(beta[i],std[i])\n",
    "#these things are huge, something is probably off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 21) (400,)\n"
     ]
    }
   ],
   "source": [
    "# 95% CI: mu +-1.96*sigma\n",
    "print(np.shape(X),np.shape(z_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ksajjad(X,z,k):\n",
    "#     m,n = np.shape(X) #Swapped these two, ask sajjad\n",
    "    n,m = np.shape(X)\n",
    "    ind = np.arange(0,n,k)\n",
    "    for i in ind:\n",
    "        X_test, z_test = X[i:(i+k),:],z[i:(i+k)]\n",
    "        if i ==0:\n",
    "            X_train,z_train = X[i+k:,:],z[i+k:]\n",
    "        elif i ==(n-k):\n",
    "            X_train,z_train = X[:i,:],z[:i]\n",
    "        else:\n",
    "            X_train = np.vstack([X[:i,:],X[i+k:,:]])\n",
    "            z_train = np.hstack([z[:i],z[i+k:]])\n",
    "        yield X_train, X_test, z_train, z_test #yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object ksajjad at 0x7fc19d494390>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ksajjad(X,z_n,5)\n",
    "# for XX,XXX,YY,YYY in ksajjad(X,z_n,5):\n",
    "#     print(\"bip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np roll method may include same points again in last roll,depending on numbers. do calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10 # number of folds\n",
    "partition = 0.2 # percentage of data to use for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kFold(k,X,z_n):\n",
    "    #shuffle data before doing the kFold\n",
    "    N=20\n",
    "    n = len(X[0,:])\n",
    "    combi = np.c_[X,z_n]\n",
    "    np.random.shuffle(combi)\n",
    "    X, z_n = combi[:,:n], combi[:,n]\n",
    "    CV = []\n",
    "    partition = 0.2 # percentage of data to use for testing\n",
    "    sMSE = 0. #sum mean squared error\n",
    "    sR2 = 0. #sum R2 score\n",
    "    zz = []\n",
    "    tt = []\n",
    "    for X_train, X_test, z_train, z_test in ksajjad(X,z_n,40):\n",
    "\n",
    "        # find parameters\n",
    "        beta = np.linalg.inv(X_train.T.dot(X_train)).dot(X_train.T).dot(z_train)\n",
    "#         beta = ols_svd(X_train,z_train,0.)\n",
    "\n",
    "        # make prediction\n",
    "        z_tilde = X_test @ beta\n",
    "        \n",
    "        zz.append(z_test)\n",
    "        tt.append(z_tilde)\n",
    "\n",
    "        CV.append(MSE(z_tilde,z_test))\n",
    "\n",
    "\n",
    "    zz = np.ravel(zz)\n",
    "    tt = np.ravel(tt)\n",
    "    order = np.argsort(zz)\n",
    "    tt = tt[order]\n",
    "    \n",
    "    return tt, CV\n",
    "\n",
    "#     return CV,bb\n",
    "#         return z_tilde\n",
    "#     print(np.shape(CV))\n",
    "#     print(CV[0][0],z_n[0])\n",
    "#     return CV\n",
    "#     return(MSE(np.matrix.flatten(np.array([CV])),z_n), R2(np.matrix.flatten(np.array([CV])),z_n),Var2(np.matrix.flatten(np.array([CV])),z_n,N),np.var(np.matrix.flatten(np.array([CV])),axis=0),Bias2(np.matrix.flatten(np.array([CV])),z_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0295461  0.02772321 0.01616413 0.01378665 0.01226013 0.01145152\n",
      " 0.01145822 0.01171705 0.01278915 0.03783879]\n",
      "[0.02952345 0.0276843  0.01612587 0.01372748 0.01219648 0.01135306\n",
      " 0.01134163 0.01155106 0.01251777 0.0173287 ]\n",
      "[2.26459641e-05 3.89093933e-05 3.82616447e-05 5.91724029e-05\n",
      " 6.36471688e-05 9.84655361e-05 1.16587844e-04 1.65993803e-04\n",
      " 2.71378790e-04 2.05100891e-02]\n"
     ]
    }
   ],
   "source": [
    "NN=5\n",
    "mpd = 10\n",
    "qq = len(z_n)\n",
    "\n",
    "order = np.argsort(z_n)\n",
    "ti = z[order]\n",
    "\n",
    "ziz = sorted(z_n)\n",
    "# NMSE = np.zeros(shape=(mpd))\n",
    "NMSE_k_mid=np.zeros(shape=(qq,mpd))\n",
    "NMSE_k = np.zeros(shape=(NN,mpd))\n",
    "NBias_mid=np.zeros(shape=(NN,mpd))\n",
    "NBias = np.zeros(shape=(mpd))\n",
    "NVar_mid=np.zeros(shape=(mpd,qq))\n",
    "NVar = np.zeros(shape=(mpd))\n",
    "moo = np.zeros(shape=(NN,mpd,qq))\n",
    "# nzfolded = test, frankefolded = model\n",
    "for l in range(NN):\n",
    "    #shuffle here\n",
    "    for i in range(mpd):\n",
    "        X = Model(x,y,i+1)\n",
    "        moo[l,i] = kFold(k,X,z_n)[0]\n",
    "        NMSE_k[l,i] = MSE(moo[l,i],ziz)\n",
    "#         bexp = np.mean() should be over all datasets for a model.\n",
    "#         NBias_mid[l,i] = np.mean(moo)\n",
    "NMSE = np.mean(NMSE_k,axis=0)\n",
    "\n",
    "bi2 = np.zeros(mpd)\n",
    "bi2m = np.zeros(shape=(mpd,qq))\n",
    "varm = np.zeros(shape=(mpd,qq))\n",
    "varr = np.zeros(mpd)\n",
    "for i in range(mpd):\n",
    "    for m in range(qq):\n",
    "        bi2m[i,m] = np.mean(moo[:,i,m])\n",
    "        varm[i,m] = np.var(moo[:,i,m])\n",
    "#         print(bi2m[i],ziz[j])\n",
    "#         print(np.shape(moo[:,i,j]))\n",
    "#         print(np.shape(bi2m))\n",
    "    bi2[i]=np.mean((ziz-bi2m[i])**2)\n",
    "    varr[i] = np.mean(varm[i])\n",
    "print(NMSE)\n",
    "print(bi2)\n",
    "print(varr)\n",
    "# print(NBias)\n",
    "#         NBias[i] = Bias2(ziz,moo)\n",
    "#         NBias[i]= np.mean(Var2(ziz,moo,20)) #this shouldnt look this good\n",
    "#         NVar[i] = 0#np.mean(Var2(ziz,moo,100))\n",
    "#         NBias[i] = np.mean((ti-np.mean((moo-ziz)**2)))\n",
    "#         NVar[i] = np.mean(np.var(moo))\n",
    "#             NMSE_k_mid[m,i] = np.mean((moo[m]-z_n[m])**2,keepdims=True)\n",
    "#             NMSE_k[i] = np.mean(NMSE_k_mid[:,i])\n",
    "#             NBias_mid[i,m] = np.mean(moo[m])\n",
    "#             NBias[i] = np.mean((z_n[:]-NBias_mid[i,:])**2,keepdims=True)\n",
    "#             NVar_mid[i,m] = np.var(moo[m])\n",
    "#             NVar[i] = np.mean(NVar_mid[i],keepdims=True)\n",
    "\n",
    "#             NMSE_k_mid[m,i] = np.mean((Nz_folded[:,i,m].reshape(N,1)-Nfranke_folded[:,i,m].reshape(N,1))**2,keepdims=True)\n",
    "#             NMSE_k[i] = np.mean(NMSE_k_mid[:,i,j])\n",
    "#             NBias_mid[i,m] = np.mean(Nz_folded[:,j,i,m])\n",
    "#             NBias[i]=np.mean((Nfranke_folded[0,i,:].reshape(qq,1)-NBias_mid[i,:].reshape(qq,1))**2,keepdims=True)\n",
    "#             NVar_mid[i,m] = np.var(Nz_folded[:,i,m])\n",
    "#             NVar[i] = np.mean(NVar_mid[i,:].reshape(qq,1),keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ols_noise = 8\n",
    "legs = 'MSE','Bias','Bias+Var'\n",
    "plt.figure()\n",
    "# plt.plot(np.arange(1,10),NMSE_k[:9],'k')\n",
    "plt.plot(np.arange(1,11),NMSE,'k')\n",
    "plt.plot(np.arange(1,11),bi2,'r')\n",
    "plt.plot(np.arange(1,11),varr,'b')\n",
    "plt.plot(np.arange(1,11),bi2+varr,'ro')\n",
    "# plt.plot(np.arange(1,10),NBias[:9])\n",
    "# plt.plot(np.arange(1,10),NBias[:9]+NVar[:9],'ro')\n",
    "# print(NMSE_k[:9])\n",
    "plt.xlabel('Ploynomial degree')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('MSE and bias as functions of polynomial degree, CV')\n",
    "plt.legend(legs)\n",
    "plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(np.arange(1,10),NVar[:9])\n",
    "# plt.xlabel('Ploynomial degree')\n",
    "# plt.ylabel('MSE')\n",
    "# plt.title('Variance as a function of polynomial degree, CV')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.026631402812136662\n",
      "0.013338698750786866\n",
      "0.022790333034691444\n"
     ]
    }
   ],
   "source": [
    "# print(np.mean(kFold(k,X,z_n)))\n",
    "\n",
    "## SAJJAD: look at the article by mehta, page 36 for \n",
    "# bias variance tradeoff over multiple datasets\n",
    "\n",
    "#i tried returning the model values from the function above, \n",
    "# called tt, to be able to calculate bi/var stuff as Mehta.\n",
    "\n",
    "\n",
    "itera = []\n",
    "cost = []\n",
    "\n",
    "for i in range(10):\n",
    "    itera.append(kFold(k,X,z_n)[0])\n",
    "\n",
    "itera = np.array(itera)\n",
    "xi = np.mean(itera,axis=0)\n",
    "zi = sorted(z_n)\n",
    "\n",
    "for i in range(10):\n",
    "    cost.append(MSE(itera[i,:],zi))\n",
    "err = np.mean(cost)\n",
    "print(err)\n",
    "\n",
    "meann = np.mean(itera,axis=0)\n",
    "B2 = np.sum((z_n-meann)**2)\n",
    "# print(B2/len(z_n))\n",
    "\n",
    "inni =(itera-meann)**2\n",
    "\n",
    "uti = np.mean(inni,axis=0)\n",
    "vr = np.sum(uti)\n",
    "print(vr/len(z_n))\n",
    "print(np.mean(kFold(k,X,z_n)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kFoldskl(k,X,z_n):\n",
    "    from sklearn.model_selection import KFold\n",
    "    #shuffle data before doing the kFold\n",
    "    n = len(X[0,:])\n",
    "    combi = np.c_[X,z_n]\n",
    "    np.random.shuffle(combi)\n",
    "    X, z_n = combi[:,:n], combi[:,n]\n",
    "    \n",
    "#     kfold = KFold(k,True,1)\n",
    "    kfold = KFold(k,False)\n",
    "    sMSE = 0\n",
    "    sR2 = 0\n",
    "    CV = []\n",
    "    b2 = 0\n",
    "    for train,test in kfold.split(X,z_n):\n",
    "        # find parameters\n",
    "        clf = skl.LinearRegression(fit_intercept=False) #False to not center data, i.e. intercept is not 0\n",
    "        clf.fit(X[train],z_n[train]) \n",
    "\n",
    "        #make prediction\n",
    "        zpredict = clf.predict(X[test])\n",
    "        CV.append(zpredict.T)\n",
    "#         print(np.shape(zpredict))\n",
    "        \n",
    "#         sMSE += mean_squared_error(z_n[test],zpredict)\n",
    "#         sR2 += r2_score(z_n[test],zpredict)\n",
    "#     print(np.shape(CV))\n",
    "#     return sMSE/k, sR2/k\n",
    "#     print(CV[0][0],z_n[0])\n",
    "    return(MSE(np.matrix.flatten(np.array([CV])),z_n), R2(np.matrix.flatten(np.array([CV])),z_n))\n",
    "#     return MSE(zpredict,z_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "643.6368984086482\n"
     ]
    }
   ],
   "source": [
    "#function test\n",
    "a=0\n",
    "b=0\n",
    "c=0\n",
    "d=0\n",
    "b2 = 0\n",
    "itera = []\n",
    "zs = []\n",
    "k = 10\n",
    "# print(np.shape(kFold(k,X,z_n)[1]))\n",
    "uff = np.matrix.flatten(np.array([kFold(k,X,z_n)[1]]))\n",
    "# print(np.shape(uff))\n",
    "# print(kFold(k,X,z_n))\n",
    "# print(np.mean(kFold(k,X,z_n)))\n",
    "for i in range(10):\n",
    "    itera.append(np.mean(kFold(k,X,z_n)[0]))\n",
    "    zs.append(np.matrix.flatten(np.array([kFold(k,X,z_n)[1]])))\n",
    "    b2 += np.sum((z_n-np.mean(zs[i]))**2)\n",
    "print(b2)\n",
    "#     print(itera[i])\n",
    "#     print(z_n)\n",
    "#     b2 += np.sum((z_n-itera[i])**2)\n",
    "#     print(kFold(k,X,z_n))\n",
    "# print(np.mean(itera),np.std(itera),np.var(itera))\n",
    "# print(b2/100)\n",
    "# mi = np.mean(itera)\n",
    "# su =0.\n",
    "# for i in range(10):\n",
    "#     su +=(itera[i]-mi)**2\n",
    "# print(su/10.)\n",
    "# print(21./10.*0.009)\n",
    "# print(np.shape(kFold(k,X,z_n)))\n",
    "#     a1,b1 = kFold(k,X,z_n)\n",
    "#     a+=a1\n",
    "#     b+=b1\n",
    "#     c1,d1 = kFoldskl(k,X,z_n)\n",
    "#     c += c1\n",
    "#     d += d1\n",
    "# print(a/10,c/10,b/10,d/10)\n",
    "#     print(\"skl\",kFoldskl(k,X,z_n))\n",
    "#     kFold(k,X,z_n)\n",
    "#     kFoldskl(k,X,z_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kFoldRidge(k,X,z_n,_lambda):\n",
    "    #shuffle data before doing the kFold\n",
    "    n = len(X[0,:])\n",
    "    combi = np.c_[X,z_n]\n",
    "    np.random.shuffle(combi)\n",
    "    X, z_n = combi[:,:n], combi[:,n]\n",
    "    \n",
    "    partition = 0.2 # percentage of data to use for testing\n",
    "    sMSE = 0 #sum mean squared error\n",
    "    sR2 = 0 #sum R2 score\n",
    "    \n",
    "    for i in range(k):\n",
    "        # Split data\n",
    "        X_train,X_test,z_train,z_test = train_test_split(X,z_n,test_size=partition,shuffle=False)\n",
    "        \n",
    "        # find parameters\n",
    "#         beta = np.linalg.inv(X_train.T.dot(X_train)-_lambda*np.eye(len(X[0][:]))).dot(X_train.T).dot(z_train)\n",
    "\n",
    "        beta = np.linalg.inv(X_train.T.dot(X_train)-_lambda*np.eye(n)).dot(X_train.T).dot(z_train)\n",
    "\n",
    "        # make prediction\n",
    "        z_tilde = X_test @ beta\n",
    "\n",
    "        # sum of MSE and R2, remember to divide by k later\n",
    "        sMSE += MSE(z_test,z_tilde)\n",
    "        sR2 += R2(z_test,z_tilde)\n",
    "\n",
    "        # Prepare data for next fold\n",
    "        X = np.roll(X,len(X_test),axis=0) # Rolls matrix downwards before next split\n",
    "        z_n = np.roll(z_n,len(z_test)) # Roll\n",
    "    \n",
    "    return sMSE/k, sR2/k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.012265031983984586, 0.8531054494832586)\n",
      "[ 6.58553608e-02  2.10245379e-02  1.37286245e-01  1.35261437e-01\n",
      "  1.62219821e-02  1.99704312e-02  9.85229430e-02  1.04823205e-02\n",
      "  5.65709356e-02  1.02261417e-02  1.85494408e-02  1.03479756e-01\n",
      "  1.35759234e-01  6.44605906e-03  7.49619689e-03  3.43742432e-02\n",
      "  5.62100939e-02  6.07884679e-02  3.58380831e-02  6.02620677e-02\n",
      "  1.20733359e-01  1.60821694e-01  1.49539823e-01  1.24879924e-01\n",
      " -1.97000202e-02  8.81192564e-02  8.36265460e-02  2.44538495e-02\n",
      "  8.44961657e-02  4.39572152e-02  5.47220308e-02  1.99947318e-03\n",
      "  6.03841908e-02  3.13205086e-02  3.55675188e-02  1.26080798e-02\n",
      "  1.27397146e-01  1.80602853e-01  5.50085486e-02  1.62560834e-01\n",
      " -1.89033330e-02  1.96264585e-01  1.47773021e-01  1.08983905e-01\n",
      "  1.71964055e-01  1.28675481e-01  1.26138929e-01  1.25163443e-01\n",
      "  1.53225392e-01 -3.53742165e-03  1.23008255e-01  1.02978287e-01\n",
      "  5.71432265e-02  1.28805350e-01 -1.52427069e-04  1.43922015e-01\n",
      "  1.78242772e-03  1.23489848e-01  3.55276779e-02  2.17410532e-01\n",
      "  1.24982159e-01  8.59948225e-02  1.55771189e-01  7.02181081e-02\n",
      "  2.78173997e-01  1.76487045e-01  1.29675576e-01  8.70708501e-02\n",
      "  2.00386000e-01  1.97997282e-01  7.11741785e-03  1.79147764e-01\n",
      "  1.22562317e-01  1.73176635e-01  1.20554247e-01  1.67532647e-01\n",
      "  1.62882914e-01  4.48602922e-02  8.51343151e-03  2.51128165e-01\n",
      " -1.16247076e-02  1.57350741e-01 -2.13550291e-03  1.15929293e-01\n",
      "  1.94119132e-02  2.74239810e-01  2.57087182e-01  1.39363163e-01\n",
      "  1.38206815e-02  7.92263583e-03  1.25372570e-01  1.81715022e-01\n",
      "  1.98908075e-01  7.16299251e-02  4.68900274e-02  1.50083488e-01\n",
      "  3.21470183e-01  1.65304356e-01  1.71577650e-01  1.16157442e-01\n",
      "  1.31162423e-01  1.38358485e-01  9.71698783e-02  8.58357507e-02\n",
      "  1.22559776e-01  1.14695929e-01  1.68972320e-01  1.12809547e-01\n",
      "  9.16198446e-02  2.23044564e-01  1.37922248e-01  3.17624189e-01\n",
      "  2.55744117e-01  1.62445507e-01  2.94643449e-01  2.30631727e-01\n",
      " -3.80855915e-03  1.96068862e-01  7.58555908e-02  1.28641777e-01\n",
      "  2.47055587e-02  2.46029281e-01  2.76719556e-01  1.79760251e-01\n",
      "  1.45320169e-01  8.75713591e-02  2.61159834e-01  7.53449223e-03\n",
      "  2.16984518e-01  1.26609967e-01  1.32435182e-01  2.44416019e-01\n",
      "  9.30088341e-02  1.61179597e-01 -1.18723811e-03  2.84211055e-02\n",
      " -1.61458374e-03  1.29639645e-01  9.59881728e-02  2.07192873e-01\n",
      "  7.11459815e-02  1.05036243e-01 -2.21444028e-03  1.66663049e-01\n",
      "  2.43623488e-01  2.48615406e-01  2.33964651e-01  1.17242637e-01\n",
      "  4.12707455e-02  2.34931367e-01  1.17291406e-01  2.09494015e-01\n",
      "  2.55653163e-01  7.31472676e-02  2.31024702e-01  3.25023739e-01\n",
      "  2.80363737e-01  1.70383293e-01  1.20194094e-01  3.28651117e-01\n",
      "  1.12358418e-01  2.64678111e-01  1.83450756e-01  9.05019057e-02\n",
      "  2.37785729e-02  1.67221985e-01  2.41367893e-01  2.35883140e-01\n",
      "  1.26394243e-01  1.54300807e-01  2.89407522e-01  2.70224493e-01\n",
      "  1.87076681e-01  2.10361252e-01  3.11838353e-01  3.28008013e-01\n",
      "  1.63268042e-01  2.25633283e-01  6.81951793e-02  2.42770285e-01\n",
      "  1.25179598e-01  1.37756291e-01  1.96091453e-01  2.29571544e-01\n",
      "  3.02712158e-01  1.92112066e-01  1.56462581e-01  1.22621221e-01\n",
      "  1.90899787e-01  1.92462428e-01  1.48038058e-01  2.80654376e-01\n",
      "  2.47809503e-01  1.52275560e-01  9.69592862e-02  2.21329405e-01\n",
      "  2.65405672e-01  4.66427350e-02  3.12415711e-01  3.02368743e-01\n",
      "  2.15315126e-01  8.71259795e-02  4.42233424e-01  1.74680869e-01\n",
      "  1.71967462e-01  2.19262352e-01  1.18589723e-01  1.73534031e-01\n",
      "  1.19139262e-01  2.50559587e-01  1.45039002e-01  2.26152966e-01\n",
      "  1.67027704e-01  1.89712614e-01  2.43029761e-01  3.30615037e-01\n",
      "  2.73241675e-01  2.77075992e-01  1.67440012e-01  1.89721539e-01\n",
      "  2.34635537e-01  3.55139805e-01  1.80226558e-01  1.34338232e-01\n",
      "  3.23844938e-01  1.99298181e-01  2.55660422e-01  9.03911127e-02\n",
      "  2.52361909e-01  2.77855397e-01  1.59795106e-01  1.32299909e-01\n",
      "  2.06542544e-01  3.28866470e-01  1.52168142e-01  2.39697644e-01\n",
      "  3.70007509e-01  1.49317420e-01  2.62045874e-01  2.44857869e-01\n",
      "  1.58155644e-01  2.72689460e-01  3.72971485e-01  3.63195305e-01\n",
      "  3.17569718e-01  2.24839487e-01  2.18505312e-01  2.06659573e-01\n",
      "  3.17504181e-01  1.89236749e-01  2.76148952e-01  1.97721036e-01\n",
      "  3.08009623e-01  2.35427900e-01  6.29022534e-01  3.27389442e-01\n",
      "  2.93508182e-01  4.97968987e-01  1.94272376e-01  3.33408065e-01\n",
      "  3.55231458e-01  2.75490665e-01  3.98936327e-01  4.95974553e-01\n",
      "  3.18222246e-01  2.34989951e-01  2.30308490e-01  2.29863548e-01\n",
      "  2.69891284e-01  3.44345065e-01  2.36814931e-01  3.49721916e-01\n",
      "  3.98703655e-01  2.42046232e-01  2.24531833e-01  2.44807110e-01\n",
      "  3.14534781e-01  1.02181914e-01  1.16615979e-01  1.61814150e-01\n",
      "  3.55339566e-01  3.11364950e-01  2.58969770e-01  2.45607899e-01\n",
      "  2.04426567e-01  2.65993659e-01  2.63307326e-01  2.39219453e-01\n",
      "  2.13131326e-01  2.41141668e-01  2.19448586e-01  2.85992072e-01\n",
      "  2.70326526e-01  2.61546837e-01  2.65700673e-01  2.18741753e-01\n",
      "  3.19220730e-01  3.29894342e-01  3.51827569e-01  3.29844047e-01\n",
      "  5.48886246e-01  2.69883865e-01  2.98846549e-01  2.83493314e-01\n",
      "  2.99903007e-01  3.14994025e-01  4.40412098e-01  2.27839428e-01\n",
      "  3.36364323e-01  5.59477483e-01  2.28678451e-01  4.30825113e-01\n",
      "  2.90383881e-01  2.27956768e-01  3.02709134e-01  1.61355009e-01\n",
      "  2.94401383e-01  2.79380832e-01  3.57262887e-01  2.50080796e-01\n",
      "  2.50773674e-01  3.03826758e-01  2.20083015e-01  4.45805206e-01\n",
      "  4.85524667e-01  2.02034057e-01  6.70387807e-01  5.05401495e-01\n",
      "  3.89652747e-01  3.19779566e-01  3.97427875e-01  5.23579064e-01\n",
      "  5.16622519e-01  4.82194304e-01  5.57947112e-01  3.84781110e-01\n",
      "  6.17756947e-01  5.04017769e-01  4.59316873e-01  1.96838676e-01\n",
      "  4.33886546e-01  4.58553813e-01  4.43215916e-01  7.10522921e-01\n",
      "  5.84861466e-01  2.78628483e-01  4.90618925e-01  3.50500187e-01\n",
      "  4.73959508e-01  6.22221615e-01  5.74396664e-01  5.99645001e-01\n",
      "  3.43656357e-01  5.93196824e-01  5.05401367e-01  4.82869426e-01\n",
      "  5.59336890e-01  4.86689635e-01  5.21347285e-01  3.05725575e-01\n",
      "  4.41326063e-01  4.36931561e-01  6.96038947e-01  6.79642482e-01\n",
      "  6.06820201e-01  6.86332927e-01  1.05870035e+00  9.89840261e-01\n",
      "  1.06029945e+00  9.13491997e-01  9.87128183e-01  9.72689487e-01\n",
      "  8.43280301e-01  1.06222770e+00  1.01607273e+00  1.14112049e+00\n",
      "  8.92205176e-01  1.14037961e+00  1.19717159e+00  1.13174255e+00\n",
      "  1.07027643e+00  1.20409112e+00  1.02482682e+00  1.08292284e+00\n",
      "  1.10428096e+00  1.09292368e+00  1.09105813e+00  1.00654926e+00\n",
      "  1.17586715e+00  1.11246508e+00  1.05928714e+00  1.15683494e+00\n",
      "  1.15631978e+00  1.11303187e+00  1.05856992e+00  1.13912826e+00\n",
      "  1.00231083e+00  1.10805403e+00  1.11146133e+00  1.15502936e+00]\n"
     ]
    }
   ],
   "source": [
    "print(kFoldRidge(k,X,z_n,0.))\n",
    "print(kFold(k,X,z_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kFoldLassoCV(k,X,z_n,_lambda):\n",
    "    partition = 0.2 #Percentage of data to use for testing\n",
    "\n",
    "    #How to select good tolerances and max iters?\n",
    "    reg = skl.LassoCV(alphas=_lambda,cv = k, random_state = 0,tol=0.0001,max_iter = 100000).fit(X,z_n)\n",
    "    ztilde = reg.predict(X)\n",
    "    plt.figure()\n",
    "    plt.semilogx(reg.alphas_,reg.mse_path_)\n",
    "    plt.semilogx(reg.alphas_,reg.mse_path_.mean(axis=-1),'k')\n",
    "    plt.xlabel('Log-plot of lambdas')\n",
    "    plt.ylabel('Mean squared error')\n",
    "    plt.show()\n",
    "    \n",
    "    return mean_squared_error(ztilde,z_n), r2_score(ztilde,z_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kFoldLasso(k,X,z_n,_lambda):\n",
    "    # this converges slowly for small lambda!\n",
    "    \n",
    "    #shuffle data before doing the kFold\n",
    "    n = len(X[0,:])\n",
    "    combi = np.c_[X,z_n]\n",
    "    np.random.shuffle(combi)\n",
    "    X, z_n = combi[:,:n], combi[:,n]\n",
    "    \n",
    "    #dont need to shuffle, as traintestsplit picks random?\n",
    "    \n",
    "    partition = 0.2 # percentage of data to use for testing\n",
    "    sMSE = 0 #sum mean squared error\n",
    "    sR2 = 0 #sum R2 score\n",
    "    \n",
    "    for i in range(k):\n",
    "        X_train, X_test, z_train, z_test = train_test_split(X,z_n,test_size=partition,shuffle=False )\n",
    "\n",
    "        lass = skl.Lasso(alpha=_lambda,tol = 0.0001,max_iter = 100000)\n",
    "        lass.fit(X_train,z_train)\n",
    "        z_tilde = lass.predict(X_test)\n",
    "\n",
    "#         # sum of MSE and R2, remember to divide by k later\n",
    "        sMSE += mean_squared_error(z_test,z_tilde)\n",
    "        sR2 += r2_score(z_test,z_tilde)\n",
    "\n",
    "        # Prepare data for next fold\n",
    "        X = np.roll(X,len(X_test),axis=0) # Rolls matrix downwards before next split\n",
    "        z_n = np.roll(z_n,len(z_test)) # Roll\n",
    "    \n",
    "    return sMSE/k, sR2/k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-7fc9c03c32bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMPD\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mdMSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdR2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m#     dMSE, dR2 = NoResampling(X,z_n,0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#     dMSE,dR2 = kFoldskl(k,X,z_n)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "MPD = np.arange(9)+1#np.arange(9)+1\n",
    "MSE_degree = []\n",
    "\n",
    "\n",
    "#shuffle data before doing the kFold\n",
    "n = len(X[0,:])\n",
    "combi = np.c_[X,z_n]\n",
    "np.random.shuffle(combi)\n",
    "X, z_n = combi[:,:n], combi[:,n]\n",
    "for i in MPD:\n",
    "    X = Model(x,y,i)\n",
    "    dMSE, dR2 = kFold(k,X,z_n)\n",
    "#     dMSE, dR2 = NoResampling(X,z_n,0)\n",
    "#     dMSE,dR2 = kFoldskl(k,X,z_n)\n",
    "    print(i,dMSE)\n",
    "    MSE_degree.append(dMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(MPD+1,MSE_degree)\n",
    "plt.xlabel('Polynomial degree')\n",
    "plt.ylabel('Mean squared error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems the model complexity isnt high enough for the curve to have a minimum like Hastie 2.11. To increase model complexity, a different inversion method is required, due to round-off-error, or what its called."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_lambda = np.logspace(-4,5,10)\n",
    "\n",
    "RidgeMSE = np.zeros((len(MPD),len(_lambda)))\n",
    "RidgeR2 = np.zeros((len(MPD),len(_lambda)))\n",
    "\n",
    "\n",
    "\n",
    "for i,mpd in enumerate(MPD):\n",
    "    X = Model(x,y,mpd)\n",
    "    for j,lam in enumerate(_lambda):\n",
    "#         rMSE,rR2 = NoResampling(X,z_n,lam)\n",
    "        rMSE,rR2 = kFoldRidge(k,X,z_n,lam)\n",
    "        RidgeMSE[i][j] = rMSE\n",
    "        RidgeR2[i][j] = rR2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "for i in range(len(_lambda)):\n",
    "    plt.semilogy(MPD,RidgeMSE[:,i],label=_lambda[i])\n",
    "plt.xlabel('Polynomial degree')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "for i in range(len(MPD)):\n",
    "    plt.loglog(_lambda,RidgeMSE[i,:],label=i+1)\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'll use Scikit-learn as recommended for this\n",
    "kFoldLassoCV(k,X,z_n,_lambda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#morten spm:\n",
    "# confidence interval\n",
    "# bias variance: \n",
    "#use each fold to make mean, or run 10 shuffled k-folds?\n",
    "#lambdas are usually horrible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
